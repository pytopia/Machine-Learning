{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning is a powerful approach in machine learning that combines multiple models to create a more robust and accurate predictive system. This technique has gained significant popularity due to its ability to improve model performance and generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning is a machine learning paradigm where multiple models (often called \"weak learners\" or \"base models\") are trained to solve the same problem and combined to get better results. The main idea behind ensemble methods is that a group of weak learners can come together to form a strong learner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ensemble-learning.webp\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** Think of ensemble learning as a \"committee\" of models making decisions together, rather than relying on a single model's judgment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental principle of ensemble learning is to leverage the \"wisdom of the crowd.\" In machine learning terms, this means:\n",
    "\n",
    "1. Training multiple models on the same or slightly different datasets\n",
    "2. Using various algorithms or variations of the same algorithm\n",
    "3. Combining the predictions of these models in a way that reduces the overall error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble's prediction is typically more accurate than any individual model's prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of ensemble methods, but the three main categories are:\n",
    "\n",
    "1. **Bagging (Bootstrap Aggregating)**: Creates multiple subsets of the original dataset through random sampling with replacement, trains a model on each subset, and combines predictions through voting or averaging.\n",
    "\n",
    "2. **Boosting**: Trains models sequentially, with each new model focusing on the errors of the previous ones. It assigns higher weights to misclassified instances.\n",
    "\n",
    "3. **Stacking**: Uses predictions from multiple models as inputs to a final \"meta-model\" that learns how to best combine these predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple ensemble of $N$ classifiers. For a given input $x$, each classifier $h_i(x)$ produces a prediction. The final prediction $H(x)$ of the ensemble can be represented as:\n",
    "\n",
    "For classification tasks:\n",
    "$$H(x) = \\text{mode}(h_1(x), h_2(x), ..., h_N(x))$$ \n",
    "\n",
    "For regression tasks:\n",
    "$$H(x) = \\frac{1}{N} \\sum_{i=1}^N h_i(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the concept, let's consider a binary classification problem with three weak classifiers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble prediction for x = 0.55: 1\n"
     ]
    }
   ],
   "source": [
    "def weak_classifier1(x):\n",
    "    return 1 if x > 0.5 else 0\n",
    "\n",
    "def weak_classifier2(x):\n",
    "    return 1 if x > 0.6 else 0\n",
    "\n",
    "def weak_classifier3(x):\n",
    "    return 1 if x > 0.4 else 0\n",
    "\n",
    "def ensemble_classifier(x):\n",
    "    votes = [weak_classifier1(x), weak_classifier2(x), weak_classifier3(x)]\n",
    "    return 1 if sum(votes) > len(votes) / 2 else 0\n",
    "\n",
    "# Example usage\n",
    "x = 0.55\n",
    "print(f\"Ensemble prediction for x = {x}: {ensemble_classifier(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the ensemble makes a decision based on the majority vote of the three weak classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While this example uses simple threshold-based classifiers, in practice, ensemble methods often use more sophisticated base models like decision trees, neural networks, or support vector machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning is a versatile and powerful technique in machine learning. As we delve deeper into specific ensemble methods in the following sections, we'll explore how these principles are applied in various algorithms and their practical implications in solving real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [The Wisdom of the Crowd: Why Ensemble Methods Work](#toc1_)    \n",
    "  - [The Wisdom of the Crowd Phenomenon](#toc1_1_)    \n",
    "  - [Statistical Reasons for Ensemble Effectiveness](#toc1_2_)    \n",
    "  - [Diversity and Decorrelation](#toc1_3_)    \n",
    "  - [Overcoming Individual Model Weaknesses](#toc1_4_)    \n",
    "  - [Practical Example: Voting Classifier](#toc1_5_)    \n",
    "- [Types of Ensemble Methods](#toc2_)    \n",
    "  - [Parallel Ensemble Methods](#toc2_1_)    \n",
    "    - [Bagging (Bootstrap Aggregating)](#toc2_1_1_)    \n",
    "    - [Random Forests](#toc2_1_2_)    \n",
    "    - [Extra Trees (Extremely Randomized Trees)](#toc2_1_3_)    \n",
    "  - [Sequential Ensemble Methods](#toc2_2_)    \n",
    "    - [Boosting](#toc2_2_1_)    \n",
    "  - [Stacking (Stacked Generalization)](#toc2_3_)    \n",
    "  - [Voting Ensembles](#toc2_4_)    \n",
    "  - [Practical Example: Comparing Ensemble Methods](#toc2_5_)    \n",
    "- [Advantages and Challenges of Ensemble Methods](#toc3_)    \n",
    "  - [Advantages of Ensemble Methods](#toc3_1_)    \n",
    "  - [Challenges and Considerations](#toc3_2_)    \n",
    "- [Ensemble Diversity: Key to Success](#toc4_)    \n",
    "  - [Methods to Introduce Diversity](#toc4_1_)    \n",
    "  - [Measuring and Optimizing Diversity](#toc4_2_)    \n",
    "  - [Practical Implementation](#toc4_3_)    \n",
    "  - [Monitoring and Evaluation](#toc4_4_)    \n",
    "- [Combining Predictions in Ensembles](#toc5_)    \n",
    "  - [Voting Mechanisms](#toc5_1_)    \n",
    "  - [Weighted Combination Methods](#toc5_2_)    \n",
    "  - [Model Calibration](#toc5_3_)    \n",
    "  - [Error Correlation and Diversity](#toc5_4_)    \n",
    "  - [Best Practices for Combining Predictions](#toc5_5_)    \n",
    "- [Evaluating Ensemble Models](#toc6_)    \n",
    "  - [Ensemble-Specific Metrics](#toc6_1_)    \n",
    "  - [Cross-Validation Strategies](#toc6_2_)    \n",
    "- [Summary](#toc7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[The Wisdom of the Crowd: Why Ensemble Methods Work](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods have proven to be remarkably effective in improving machine learning model performance. This section delves into the underlying principles that make ensemble methods so powerful, drawing parallels with the concept of \"wisdom of the crowd\" from social science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[The Wisdom of the Crowd Phenomenon](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term \"wisdom of the crowd\" was popularized by James Surowiecki in his 2004 book of the same name. It refers to the phenomenon where the collective opinion of a group of individuals is often more accurate than the opinion of any single expert. This concept has found its way into machine learning through ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/wisdom.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of machine learning, the \"crowd\" consists of multiple models or learners, each with its own strengths and weaknesses. By combining these diverse models, we can often achieve better overall performance than any single model could provide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Statistical Reasons for Ensemble Effectiveness](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several statistical reasons why ensemble methods tend to outperform individual models:\n",
    "\n",
    "1. **Reduction of Variance**: Ensemble methods, particularly bagging techniques, help reduce the variance of the model. By training multiple models on different subsets of the data, we can average out the fluctuations caused by the specific choice of training data.\n",
    "\n",
    "2. **Reduction of Bias**: Some ensemble methods, like boosting, can reduce bias by sequentially focusing on the errors of previous models. This allows the ensemble to learn more complex patterns than any single model might be capable of capturing.\n",
    "\n",
    "3. **Expanded Hypothesis Space**: By combining multiple models, ensemble methods can effectively search a larger space of possible hypotheses. This increases the likelihood of finding a good approximation of the true underlying function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_'></a>[Diversity and Decorrelation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key factor in the success of ensemble methods is the diversity of the base models. If all models make the same mistakes, combining them won't yield any benefit. The goal is to have models that make different errors, so that when combined, they can correct each other's mistakes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/diverse-predictors.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to introduce diversity in an ensemble:\n",
    "\n",
    "1. **Data Sampling**: Using different subsets of the training data for each model (as in bagging).\n",
    "2. **Feature Sampling**: Using different subsets of features for each model (as in Random Forests).\n",
    "3. **Algorithm Diversity**: Using different types of models or different hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of decorrelation is closely related to diversity. The correlation between errors of different models in the ensemble should be as low as possible for maximum effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_'></a>[Overcoming Individual Model Weaknesses](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods can often overcome the limitations of individual models:\n",
    "\n",
    "1. **Handling Complex Decision Boundaries**: While a single model might struggle with complex decision boundaries, an ensemble can approximate complex functions by combining simpler models.\n",
    "\n",
    "2. **Robustness to Outliers**: Ensemble methods can be more robust to outliers and noise in the data, as the impact of any single datapoint is reduced through the combination of multiple models.\n",
    "\n",
    "3. **Handling Imbalanced Datasets**: Some ensemble methods, like boosting, can effectively handle imbalanced datasets by focusing on misclassified examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** When designing an ensemble, aim for a diverse set of base models that make uncorrelated errors. This maximizes the benefit of combining their predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_'></a>[Practical Example: Voting Classifier](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the concept, let's consider a simple voting classifier ensemble using scikit-learn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "model1 = LogisticRegression(random_state=42)\n",
    "model2 = DecisionTreeClassifier(random_state=42)\n",
    "model3 = SVC(probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(random_state=42)),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC(probability=True, random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VotingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(random_state=42)),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC(probability=True, random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42)),\n",
       "                             ('svc', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"lr\", model1), (\"dt\", model2), (\"svc\", model3)], voting=\"soft\"\n",
    ")\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and calculate accuracy\n",
    "y_pred = ensemble.predict(X_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr Accuracy: 0.8250\n",
      "dt Accuracy: 0.7900\n",
      "svc Accuracy: 0.9350\n"
     ]
    }
   ],
   "source": [
    "# Compare with individual model accuracies\n",
    "for name, model in ensemble.named_estimators_.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how an ensemble of diverse models (logistic regression, decision tree, and support vector machine) can potentially outperform any individual model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While ensemble methods are powerful, they are not a silver bullet. They can be computationally expensive and may lead to overfitting if not properly regularized. Always consider the trade-offs between model complexity, computational resources, and performance gains when deciding to use ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections, we'll explore specific ensemble techniques in more detail, including bagging, boosting, and stacking, to see how these principles are applied in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Types of Ensemble Methods](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods in machine learning can be categorized into several types, each with its own unique approach to combining multiple models. In this section, we'll explore the main types of ensemble methods, their characteristics, and how they leverage the collective power of multiple models to improve predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Parallel Ensemble Methods](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel ensemble methods involve creating multiple independent models and combining their predictions. These methods are often easier to implement and can be parallelized for faster computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_'></a>[Bagging (Bootstrap Aggregating)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is one of the earliest and most intuitive ensemble techniques. It involves:\n",
    "\n",
    "1. Creating multiple subsets of the original dataset through random sampling with replacement (bootstrap sampling).\n",
    "2. Training a separate model on each subset.\n",
    "3. Combining predictions through voting (for classification) or averaging (for regression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/bagging.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical representation for bagging in regression:\n",
    "\n",
    "$$f_{bag}(x) = \\frac{1}{B} \\sum_{i=1}^B f_i(x)$$\n",
    "\n",
    "Where $B$ is the number of bootstrap samples, and $f_i(x)$ is the prediction of the $i$-th model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** Bagging is particularly effective for high-variance models like decision trees, as it helps reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_2_'></a>[Random Forests](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are an extension of bagging specifically designed for decision trees. They introduce an additional layer of randomness:\n",
    "\n",
    "1. Create bootstrap samples of the dataset.\n",
    "2. For each sample, train a decision tree, but at each node, only consider a random subset of features for splitting.\n",
    "3. Combine predictions through voting or averaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/random-forest.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference from bagging is the feature subsampling, which decorrelates the trees and further reduces variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_3_'></a>[Extra Trees (Extremely Randomized Trees)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees take the randomization in Random Forests one step further:\n",
    "\n",
    "1. Use the entire training set (no bootstrap sampling).\n",
    "2. At each node, randomly select features and split points.\n",
    "3. Choose the best split among these random splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/extra-trees.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This increased randomness can lead to lower variance but potentially higher bias compared to Random Forests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Sequential Ensemble Methods](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential ensemble methods train models in a sequence, with each subsequent model trying to correct the errors of the previous ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_'></a>[Boosting](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is a family of algorithms that convert weak learners into strong learners. The key ideas are:\n",
    "\n",
    "1. Train models sequentially.\n",
    "2. Each new model focuses on the errors of the previous ensemble.\n",
    "3. Assign higher weights to misclassified instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/boosting.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some popular boosting algorithms include:\n",
    "\n",
    "- **AdaBoost (Adaptive Boosting)**: Adjusts the weights of misclassified instances and the weights of classifiers in the ensemble.\n",
    "- **Gradient Boosting**: Trains each model to predict the residuals (errors) of the previous models.\n",
    "- **XGBoost, LightGBM, CatBoost**: Advanced implementations of gradient boosting with optimizations for speed and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical representation for gradient boosting:\n",
    "\n",
    "$$F_m(x) = F_{m-1}(x) + \\alpha_m h_m(x)$$\n",
    "\n",
    "Where $F_m(x)$ is the model at iteration $m$, $h_m(x)$ is the weak learner, and $\\alpha_m$ is the weight assigned to this learner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While boosting can achieve high accuracy, it can be prone to overfitting, especially on noisy datasets. Proper regularization and early stopping are crucial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[Stacking (Stacked Generalization)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is a meta-learning approach that involves:\n",
    "\n",
    "1. Training multiple diverse base models.\n",
    "2. Using their predictions as features for a higher-level model (meta-model).\n",
    "3. The meta-model learns how to best combine the predictions of the base models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/stacking.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/stacking-2.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, for base models $f_1, f_2, ..., f_k$ and meta-model $g$, the stacked prediction is:\n",
    "\n",
    "$$f_{stack}(x) = g(f_1(x), f_2(x), ..., f_k(x))$$\n",
    "\n",
    "Stacking can often achieve better performance than any of the individual models, but it requires careful cross-validation to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_'></a>[Voting Ensembles](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting ensembles combine predictions from multiple models through voting mechanisms:\n",
    "\n",
    "1. **Hard Voting**: Each model makes a prediction (vote), and the class with the most votes wins.\n",
    "2. **Soft Voting**: Models provide probability estimates for each class, which are averaged, and the class with the highest average probability is chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/voting.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/soft-hard-voting.ppm\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, for soft voting with $K$ models:\n",
    "\n",
    "$$P(y|x) = \\frac{1}{K} \\sum_{i=1}^K P_i(y|x)$$\n",
    "\n",
    "Where $P_i(y|x)$ is the probability estimate from the $i$-th model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_5_'></a>[Practical Example: Comparing Ensemble Methods](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement and compare different ensemble methods using scikit-learn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Accuracy: 0.9160 (+/- 0.0331)\n",
      "Gradient Boosting - Mean Accuracy: 0.9010 (+/- 0.0662)\n",
      "Decision Tree - Mean Accuracy: 0.7850 (+/- 0.0494)\n",
      "Logistic Regression - Mean Accuracy: 0.8110 (+/- 0.0325)\n",
      "Voting Ensemble - Mean Accuracy: 0.8730 (+/- 0.0771)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "                           n_redundant=5, random_state=42)\n",
    "\n",
    "# Define models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create a voting ensemble\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('dt', dt), ('lr', lr)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [rf, gb, dt, lr, voting]\n",
    "model_names = ['Random Forest', 'Gradient Boosting', 'Decision Tree', 'Logistic Regression', 'Voting Ensemble']\n",
    "\n",
    "# Perform cross-validation and print results\n",
    "for model, name in zip(models, model_names):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} - Mean Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how different ensemble methods compare to individual models and a voting ensemble. The results will likely show that ensemble methods (Random Forest, Gradient Boosting, and Voting Ensemble) outperform individual models like Decision Tree and Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent sections, we'll dive deeper into specific ensemble techniques, exploring their algorithms, advantages, and practical implementations in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Advantages and Challenges of Ensemble Methods](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods have gained significant popularity in machine learning due to their ability to improve model performance. However, like any technique, they come with their own set of advantages and challenges. Understanding these can help practitioners make informed decisions about when and how to use ensemble methods effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_'></a>[Advantages of Ensemble Methods](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Improved Prediction Accuracy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the primary benefits of ensemble methods is their ability to achieve higher prediction accuracy compared to individual models. By combining multiple models, ensembles can capture a broader range of patterns in the data and reduce the impact of individual model errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, this can be demonstrated using the bias-variance decomposition. For a given ensemble of $M$ independent models with equal weights, the mean squared error (MSE) of the ensemble is:\n",
    "\n",
    "$$MSE_{ensemble} = Bias^2 + \\frac{1}{M}Variance$$\n",
    "\n",
    "As $M$ increases, the variance component decreases, leading to lower overall error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Better Generalization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods often exhibit better generalization to unseen data. By combining diverse models, ensembles can reduce overfitting that might occur with individual models. This is particularly true for techniques like bagging, which use different subsets of the training data for each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Robustness to Outliers and Noise**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods can be more robust to outliers and noise in the data. For example, in a voting ensemble, the impact of a single model making an incorrect prediction due to an outlier is mitigated by the collective decision of all models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Handling of Complex Relationships**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles can capture complex, non-linear relationships in the data that might be difficult for a single model to learn. For instance, a combination of linear models and decision trees in an ensemble can model both linear and non-linear patterns effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** When dealing with high-dimensional data, ensemble methods that incorporate feature selection or importance ranking can be particularly useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_'></a>[Challenges and Considerations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Increased Computational Complexity**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods typically require training and storing multiple models, which can significantly increase computational requirements, both in terms of training time and memory usage. This can be a challenge when working with large datasets or in resource-constrained environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Risk of Overfitting**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ensembles can help reduce overfitting, they are not immune to it. If not properly tuned, ensemble methods (especially boosting algorithms) can overfit the training data. This is particularly true when using complex base models or when the ensemble size is too large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Reduced Interpretability**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble models, especially those combining different types of algorithms, can be more difficult to interpret than single models. This \"black box\" nature can be a drawback in applications where model interpretability is crucial, such as in healthcare or finance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Increased Model Complexity**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of ensemble models can make them more challenging to deploy and maintain in production environments. This includes issues related to version control, model updates, and explaining predictions to stakeholders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Hyperparameter Tuning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods often introduce additional hyperparameters (e.g., number of models, learning rate in boosting), which can make the model tuning process more complex and time-consuming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Storage Requirements**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing multiple models can require significant disk space, especially for large ensembles or when using complex base models. This can be a concern in environments with limited storage capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While ensemble methods offer many advantages, it's crucial to consider the specific requirements of your project, including computational resources, interpretability needs, and the complexity of the problem, when deciding whether to use ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections, we'll explore techniques for ensuring diversity in ensembles and methods for combining predictions, which are key to leveraging the full potential of ensemble learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Ensemble Diversity: Key to Success](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model diversity refers to the degree to which different models in an ensemble make uncorrelated errors. This concept is fundamental to the success of ensemble methods. When ensemble members make different types of errors on different instances, their combination can lead to better overall predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** The more diverse the models (higher ambiguity), the lower the ensemble error, provided the individual models maintain reasonable accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_'></a>[Methods to Introduce Diversity](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diversity in ensemble learning can be introduced through various techniques:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Sampling Diversity**\n",
    "- Bootstrap sampling (random sampling with replacement)\n",
    "- Different training set partitions\n",
    "- Cross-validation folds\n",
    "- Weighted sampling of instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def create_diverse_datasets(X, y, n_subsets=5):\n",
    "    n_samples = len(X)\n",
    "    datasets = []\n",
    "\n",
    "    for _ in range(n_subsets):\n",
    "        # Bootstrap sampling\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        datasets.append((X[indices], y[indices]))\n",
    "\n",
    "    return datasets\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm Diversity**\n",
    "- Using different learning algorithms\n",
    "- Varying model architectures\n",
    "- Different initialization points\n",
    "- Diverse hyperparameter settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def create_diverse_ensemble():\n",
    "    estimators = [\n",
    "        ('lr', LogisticRegression()),\n",
    "        ('svm', SVC(probability=True)),\n",
    "        ('dt', DecisionTreeClassifier()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=10))\n",
    "    ]\n",
    "\n",
    "    return VotingClassifier(estimators=estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Diversity**\n",
    "- Random feature subsets\n",
    "- Different feature transformations\n",
    "- Feature weighting\n",
    "- Principal Component Analysis (PCA) with different numbers of components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_'></a>[Measuring and Optimizing Diversity](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diversity can be measured using several metrics and approaches:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diversity Metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_disagreement(pred1, pred2):\n",
    "    \"\"\"Calculate disagreement between two model predictions\"\"\"\n",
    "    return np.mean(pred1 != pred2)\n",
    "\n",
    "def ensemble_diversity_matrix(predictions_list):\n",
    "    \"\"\"Calculate pairwise diversity matrix for ensemble members\"\"\"\n",
    "    n_models = len(predictions_list)\n",
    "    diversity_matrix = np.zeros((n_models, n_models))\n",
    "\n",
    "    for i in range(n_models):\n",
    "        for j in range(i+1, n_models):\n",
    "            div = calculate_disagreement(predictions_list[i], predictions_list[j])\n",
    "            diversity_matrix[i,j] = div\n",
    "            diversity_matrix[j,i] = div\n",
    "\n",
    "    return diversity_matrix\n",
    "\n",
    "model_1 = LogisticRegression()\n",
    "model_2 = DecisionTreeClassifier()\n",
    "model_3 = RandomForestClassifier()\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "model_1.fit(X, y)\n",
    "model_2.fit(X, y)\n",
    "model_3.fit(X, y)\n",
    "\n",
    "predictions_list = [model_1.predict(X), model_2.predict(X), model_3.predict(X)]\n",
    "diversity_matrix = ensemble_diversity_matrix(predictions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.183 0.183]\n",
      " [0.183 0.    0.   ]\n",
      " [0.183 0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(diversity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimization Strategies:**\n",
    "- Explicit diversity promotion through penalizing correlated predictions\n",
    "- Enforcing negative correlation between models\n",
    "- Using diversity metrics in model selection\n",
    "- Random initialization and varied architectural choices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_'></a>[Practical Implementation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a comprehensive example that combines the concepts discussed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseEnsemble:\n",
    "    def __init__(self, n_models=5):\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "        self.diversity_matrix = None\n",
    "\n",
    "    def create_base_models(self):\n",
    "        \"\"\"Create diverse base models with different configurations\"\"\"\n",
    "        models = []\n",
    "        models.append(DecisionTreeClassifier(max_depth=5))\n",
    "        models.append(DecisionTreeClassifier(max_depth=10))\n",
    "        models.append(LogisticRegression())\n",
    "        models.append(RandomForestClassifier(n_estimators=10))\n",
    "        models.append(SVC(probability=True))\n",
    "        return models[: self.n_models]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the ensemble with diversity monitoring\"\"\"\n",
    "        self.models = self.create_base_models()\n",
    "        predictions = []\n",
    "\n",
    "        for model in self.models:\n",
    "            # Create bootstrap sample\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_bootstrap = X[indices]\n",
    "            y_bootstrap = y[indices]\n",
    "\n",
    "            # Train model\n",
    "            model.fit(X_bootstrap, y_bootstrap)\n",
    "            predictions.append(model.predict(X))\n",
    "\n",
    "        # Calculate diversity\n",
    "        self.diversity_matrix = ensemble_diversity_matrix(predictions)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using majority voting\"\"\"\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        return np.apply_along_axis(\n",
    "            lambda x: np.bincount(x).argmax(), axis=0, arr=predictions\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While maximizing diversity is important, it should not come at the expense of individual model accuracy. The goal is to find the right balance between diversity and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Combining Predictions in Ensembles](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ensemble learning, combining predictions from multiple models is a crucial step. This section explores different methods for combining predictions, including voting mechanisms, weighted averaging, and model calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_'></a>[Voting Mechanisms](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting is one of the most fundamental ways to combine predictions from multiple models. There are several voting strategies that can be employed depending on the problem type and requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Voting (Majority Voting)**\n",
    "In hard voting, each model makes a prediction (casts a vote), and the class that receives the most votes becomes the final prediction. This is particularly useful for classification problems.\n",
    "\n",
    "$$\\hat{y} = \\text{mode}(y_1, y_2, ..., y_M)$$\n",
    "\n",
    "where $y_i$ is the prediction of the $i$-th model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Voting (Average Probability)**\n",
    "In soft voting, models provide probability estimates for each class, which are then averaged to make the final prediction. This often performs better than hard voting as it takes into account the confidence of each model.\n",
    "\n",
    "$$P(y=k|x) = \\frac{1}{M}\\sum_{i=1}^M P_i(y=k|x)$$\n",
    "\n",
    "where $P_i(y=k|x)$ is the probability estimate for class k from model i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example implementing both voting mechanisms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Accuracy: 0.976\n",
      "Soft Voting Accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create base models\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True))  # probability=True is required for soft voting\n",
    "]\n",
    "\n",
    "# Create voting classifiers\n",
    "voting_hard = VotingClassifier(estimators=estimators, voting='hard')\n",
    "voting_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
    "\n",
    "# The VotingClassifier automatically handles the voting process\n",
    "# Hard voting uses predict() method\n",
    "# Soft voting uses predict_proba() method internally\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "\n",
    "voting_hard.fit(X, y)\n",
    "voting_soft.fit(X, y)\n",
    "\n",
    "print(f\"Hard Voting Accuracy: {voting_hard.score(X, y)}\")\n",
    "print(f\"Soft Voting Accuracy: {voting_soft.score(X, y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_2_'></a>[Weighted Combination Methods](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted combinations assign different importance to different models based on their performance or expertise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Averaging**\n",
    "The final prediction is a weighted sum of individual predictions:\n",
    "\n",
    "$$\\hat{y} = \\sum_{i=1}^M w_i y_i$$\n",
    "\n",
    "where $w_i$ is the weight assigned to model i, and $\\sum w_i = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an implementation of a simple weighted ensemble:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class WeightedEnsemble:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Calculate weights based on cross-validation performance\n",
    "        # Higher performing models get higher weights\n",
    "        scores = []\n",
    "        for model in self.models:\n",
    "            # Perform 5-fold cross-validation and take mean score\n",
    "            cv_score = cross_val_score(model, X, y, cv=5).mean()\n",
    "            scores.append(cv_score)\n",
    "            model.fit(X, y)  # Fit the model on full data\n",
    "\n",
    "        # Normalize scores to get weights\n",
    "        self.weights = np.array(scores) / np.sum(scores)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Get weighted probability predictions\n",
    "        weighted_preds = np.zeros((X.shape[0], len(np.unique(y))))\n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            weighted_preds += weight * model.predict_proba(X)\n",
    "        return weighted_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_3_'></a>[Model Calibration](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When combining probability estimates from different models, it's important to ensure they are properly calibrated. Calibration refers to how well the predicted probabilities reflect the actual probabilities of events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/prob-calibration.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CalibratedClassifierCV` from scikit-learn performs probability calibration using either Isotonic regression or Logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "base_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_clf = CalibratedClassifierCV(base_clf, cv=3)\n",
    "calibrated_clf.fit(X, y)\n",
    "len(calibrated_clf.calibrated_classifiers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11009899, 0.88990101],\n",
       "       [0.0722637 , 0.9277363 ],\n",
       "       [0.92831857, 0.07168143],\n",
       "       [0.92834456, 0.07165544],\n",
       "       [0.07186088, 0.92813912]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_clf.predict_proba(X)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(cv=&#x27;prefit&#x27;, estimator=GaussianNB())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CalibratedClassifierCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.calibration.CalibratedClassifierCV.html\">?<span>Documentation for CalibratedClassifierCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CalibratedClassifierCV(cv=&#x27;prefit&#x27;, estimator=GaussianNB())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: GaussianNB</label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(cv='prefit', estimator=GaussianNB())"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "X_train, X_calib, y_train, y_calib = train_test_split(X, y, random_state=42)\n",
    "base_clf = GaussianNB()\n",
    "base_clf.fit(X_train, y_train)\n",
    "calibrated_clf = CalibratedClassifierCV(base_clf, cv=\"prefit\")\n",
    "calibrated_clf.fit(X_calib, y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(calibrated_clf.calibrated_classifiers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93677312, 0.06322688]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_clf.predict_proba([[-0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_4_'></a>[Error Correlation and Diversity](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effectiveness of ensemble combinations depends heavily on the correlation between model errors. Models with uncorrelated errors tend to perform better when combined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple way to measure prediction correlation between models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.63407053, 0.63407053],\n",
       "       [0.63407053, 1.        , 1.        ],\n",
       "       [0.63407053, 1.        , 1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_prediction_correlation(models, X):\n",
    "    \"\"\"\n",
    "    Calculate correlation matrix of model predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of fitted models\n",
    "    - X: Input features\n",
    "\n",
    "    Returns:\n",
    "    - Correlation matrix of predictions\n",
    "    \"\"\"\n",
    "    predictions = np.array([model.predict(X) for model in models])\n",
    "    return np.corrcoef(predictions)\n",
    "\n",
    "\n",
    "models = [model_1, model_2, model_3]\n",
    "calculate_prediction_correlation(models, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_5_'></a>[Best Practices for Combining Predictions](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Validation Strategy**\n",
    "   - Use separate validation sets for:\n",
    "     - Training base models\n",
    "     - Determining combination weights\n",
    "     - Final evaluation\n",
    "\n",
    "2. **Diversity Consideration**\n",
    "   - Monitor prediction correlations\n",
    "   - Include models with different learning algorithms\n",
    "   - Use different feature subsets or data sampling techniques\n",
    "\n",
    "3. **Calibration**\n",
    "   - Ensure probability estimates are well-calibrated before combining\n",
    "   - Use proper calibration techniques when necessary\n",
    "\n",
    "4. **Computational Efficiency**\n",
    "   - Consider the trade-off between ensemble size and performance\n",
    "   - Implement parallel processing for large ensembles when possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** Start with simple combination methods (like averaging or majority voting) before moving to more complex approaches. Often, simple methods perform just as well as more sophisticated ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** The choice of combination method should be based on your specific problem requirements, including:\n",
    "- The type of problem (classification vs regression)\n",
    "- The importance of probabilistic predictions\n",
    "- Computational constraints\n",
    "- Interpretability requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_'></a>[Evaluating Ensemble Models](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When evaluating ensemble models, we start with standard performance metrics but need to consider additional aspects specific to ensembles. The basic metrics include:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Classification Tasks:**\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- ROC-AUC and PR-AUC\n",
    "- Log Loss (especially important for probabilistic ensembles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Regression Tasks:**\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- R-squared Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's a comprehensive evaluation function that covers these metrics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "def evaluate_ensemble_classifier(ensemble, X, y_true):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of an ensemble classifier.\n",
    "    \n",
    "    Parameters:\n",
    "    - ensemble: Fitted ensemble model\n",
    "    - X: Feature matrix\n",
    "    - y_true: True labels\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Get predictions and probabilities\n",
    "    y_pred = ensemble.predict(X)\n",
    "    y_prob = ensemble.predict_proba(X)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'log_loss': log_loss(y_true, y_prob),\n",
    "        'roc_auc': roc_auc_score(y_true, y_prob[:, 1])  # For binary classification\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc6_1_'></a>[Ensemble-Specific Metrics](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Beyond basic metrics, ensembles require additional evaluation criteria:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. Diversity Measures**\n",
    "The degree of disagreement between ensemble members:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "def calculate_diversity(predictions_matrix):\n",
    "    \"\"\"\n",
    "    Calculate diversity metrics for ensemble predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions_matrix: Array of shape (n_models, n_samples) containing\n",
    "                        predictions from each model\n",
    "    \"\"\"\n",
    "    n_models = predictions_matrix.shape[0]\n",
    "    n_samples = predictions_matrix.shape[1]\n",
    "    \n",
    "    # Calculate disagreement matrix\n",
    "    disagreement = np.zeros((n_models, n_models))\n",
    "    for i in range(n_models):\n",
    "        for j in range(i+1, n_models):\n",
    "            disagreement[i,j] = np.mean(predictions_matrix[i] != predictions_matrix[j])\n",
    "            disagreement[j,i] = disagreement[i,j]\n",
    "    \n",
    "    return {\n",
    "        'mean_disagreement': np.mean(disagreement),\n",
    "        'disagreement_matrix': disagreement\n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2. Individual Model Contributions**\n",
    "Assessing how each model contributes to the ensemble's performance:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "def evaluate_model_contributions(ensemble, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the contribution of each model to the ensemble.\n",
    "    \"\"\"\n",
    "    base_score = ensemble.score(X, y)\n",
    "    contributions = []\n",
    "    \n",
    "    for i, model in enumerate(ensemble.estimators_):\n",
    "        # Create ensemble without current model\n",
    "        temp_preds = [est.predict(X) for j, est in enumerate(ensemble.estimators_)\n",
    "                     if j != i]\n",
    "        temp_score = accuracy_score(y, np.mean(temp_preds, axis=0) > 0.5)\n",
    "        \n",
    "        # Contribution is the difference in performance\n",
    "        contribution = base_score - temp_score\n",
    "        contributions.append(contribution)\n",
    "    \n",
    "    return contributions\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc6_2_'></a>[Cross-Validation Strategies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ensemble models require careful cross-validation to avoid overfitting:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def ensemble_cross_validate(ensemble, X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation specifically designed for ensembles.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        # Split data\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Train ensemble\n",
    "        ensemble.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        scores.append(evaluate_ensemble_classifier(ensemble, X_val, y_val))\n",
    "    \n",
    "    return scores\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_'></a>[Summary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning combines multiple models to create a more robust and accurate predictive system. Throughout this introduction, we've covered several fundamental aspects:\n",
    "\n",
    "1. **Types of Ensemble Methods**\n",
    "   - Parallel methods (Bagging, Random Forests)\n",
    "   - Sequential methods (Boosting)\n",
    "   - Stacking and meta-learning approaches\n",
    "\n",
    "2. **Diversity in Ensembles**\n",
    "   - Model diversity as a key success factor\n",
    "   - Various methods to introduce diversity\n",
    "   - Balance between diversity and individual model performance\n",
    "\n",
    "3. **Prediction Combination**\n",
    "   - Voting mechanisms (hard and soft voting)\n",
    "   - Weighted combination methods\n",
    "   - Dynamic and adaptive combination strategies\n",
    "\n",
    "4. **Evaluation Approaches**\n",
    "   - Standard performance metrics\n",
    "   - Ensemble-specific evaluation criteria\n",
    "   - Cross-validation strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware of these common mistakes:\n",
    "\n",
    "1. **Overfitting**\n",
    "   - Using too many models\n",
    "   - Over-complex combination methods\n",
    "   - Insufficient validation\n",
    "\n",
    "2. **Computational Inefficiency**\n",
    "   - Unnecessarily large ensembles\n",
    "   - Redundant model combinations\n",
    "   - Inefficient implementation\n",
    "\n",
    "3. **Poor Model Selection**\n",
    "   - Lack of diversity among base models\n",
    "   - Inappropriate base model choices\n",
    "   - Ignoring problem-specific requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deepen your understanding of ensemble methods:\n",
    "\n",
    "1. **Further Study**\n",
    "   - Explore specific ensemble algorithms in detail\n",
    "   - Study advanced combination techniques\n",
    "   - Learn about domain-specific applications\n",
    "\n",
    "2. **Practical Experience**\n",
    "   - Implement different ensemble types\n",
    "   - Experiment with various combination methods\n",
    "   - Practice with real-world datasets\n",
    "\n",
    "3. **Advanced Topics**\n",
    "   - Deep learning ensembles\n",
    "   - Online learning\n",
    "   - Distributed ensemble systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introduction to ensemble methods provides a foundation for understanding and implementing these powerful techniques. The key is to start with simple approaches and gradually incorporate more complex methods as needed for your specific problem domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that successful ensemble learning requires a balance of theoretical understanding and practical implementation skills, always guided by proper evaluation and validation strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
