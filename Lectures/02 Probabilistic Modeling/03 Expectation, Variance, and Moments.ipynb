{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation, Variance, and Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to our deep dive into the world of expectation, variance, and moments! 🎢📊\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous lecture, we explored the foundations of random variables and probability distributions. Now, we're going to take it up a notch and learn how to describe and summarize these distributions using powerful mathematical tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll discuss the following concepts:\n",
    "1. **Expected Value (Mean)**: The \"average\" outcome of a random variable\n",
    "2. **Variance and Standard Deviation**: Measures of spread or dispersion\n",
    "3. **Covariance and Correlation**: Understanding relationships between variables\n",
    "4. **Moments**: A general way to characterize distributions\n",
    "5. **Moment Generating Functions**: A powerful tool for working with moments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These concepts are crucial in data science and machine learning for several reasons:\n",
    "\n",
    "- They help us summarize and understand large datasets\n",
    "- They're fundamental to many statistical tests and models\n",
    "- They're used in feature engineering and selection\n",
    "- They're essential for understanding model performance and uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we explore these topics, try to think about how they might apply to real-world scenarios. Whether you're analyzing stock prices, predicting customer behavior, or optimizing algorithms, these tools will be invaluable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive in, let's activate our probability neurons:\n",
    "\n",
    "1. If you roll a fair six-sided die, what number do you \"expect\" to get?\n",
    "2. In a group of 100 people, would you be more surprised by everyone having the same birthday, or by no two people sharing a birthday?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep these questions in mind as we begin our journey into expectation and variance. Let's get started! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Expected Value (Mean)](#toc1_)    \n",
    "  - [Properties of Expectation](#toc1_1_)    \n",
    "  - [Real-world Application](#toc1_2_)    \n",
    "- [Variance and Standard Deviation](#toc2_)    \n",
    "  - [Properties of Variance](#toc2_1_)    \n",
    "  - [Examples and Calculations](#toc2_2_)    \n",
    "  - [Real-world Application](#toc2_3_)    \n",
    "- [Covariance and Correlation](#toc3_)    \n",
    "  - [Covariance: Measuring Relationship](#toc3_1_)    \n",
    "  - [Interpreting Covariance](#toc3_2_)    \n",
    "  - [Correlation: Standardized Covariance](#toc3_3_)    \n",
    "  - [Interpreting Correlation](#toc3_4_)    \n",
    "  - [Properties and Examples](#toc3_5_)    \n",
    "  - [Real-world Applications](#toc3_6_)    \n",
    "- [Moments of Random Variables](#toc4_)    \n",
    "  - [Central Moments](#toc4_1_)    \n",
    "  - [Relationships to Other Statistical Measures](#toc4_2_)    \n",
    "  - [Real-world Application](#toc4_3_)    \n",
    "- [Conclusion](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Expected Value (Mean)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're playing a game where you flip a coin. If it's heads, you win $10, and if it's tails, you lose $5. How much money should you expect to win (or lose) on average if you play this game many times? This is where the concept of expected value comes in handy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value, often called the mean, is the average outcome of a random variable if an experiment were repeated infinitely many times. It's a powerful tool that helps us understand the central tendency of a distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables, we calculate the expected value by summing up each possible outcome multiplied by its probability:\n",
    "- $E[X] = \\sum_{x} x \\cdot p(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables, we use integration instead:\n",
    "- $E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our coin flip game. Here's how we'd calculate the expected value:\n",
    "\n",
    "- $E[X] = 10 \\cdot P(\\text{Heads}) + (-5) \\cdot P(\\text{Tails}) = 10 \\cdot 0.5 + (-5) \\cdot 0.5 = 2.5$\n",
    "\n",
    "So, on average, you'd expect to win $2.50 per game if you played many times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Properties of Expectation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation has some useful properties that make calculations easier:\n",
    "\n",
    "1. **Linearity**: The expectation of a sum is the sum of the expectations. For example, if you played the coin flip game twice, your expected winnings would be $2.50 + $2.50 = $5.00.\n",
    "\n",
    "2. **Scaling**: If you multiply a random variable by a constant, you multiply its expectation by that constant. If the coin flip game prizes were doubled, your expected winnings would be $5.00 per game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Real-world Application](#toc0_)\n",
    "\n",
    "Expected values are crucial in many fields. Insurance companies use them to set premiums, investors use them to evaluate potential returns, and machine learning algorithms use them to make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in a recommendation system, we might calculate the expected rating a user would give to a movie based on their past ratings and the ratings of similar users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding expected values is the first step in describing probability distributions. In the next section, we'll explore how values can deviate from this average with variance and standard deviation. This will give us a more complete picture of the distribution's behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, while the expected value tells us the average outcome, individual results can (and often do) differ. It's a guide, not a guarantee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Variance and Standard Deviation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're a weather forecaster. You know that the average temperature in your city during summer is 25°C (77°F). But does this tell the whole story? What if one day it's 15°C and the next it's 35°C? This is where variance and standard deviation come into play.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance measures how far a set of numbers are spread out from their average value. It gives us an idea of the variability in our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a random variable X with expected value E[X], the variance is defined as:\n",
    "\n",
    "- $Var(X) = E[(X - E[X])^2]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables:\n",
    "- $Var(X) = \\sum_x (x - E[X])^2 \\cdot p(x)$\n",
    "\n",
    "For continuous random variables:\n",
    "- $Var(X) = \\int_{-\\infty}^{\\infty} (x - E[X])^2 \\cdot f(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is simply the square root of the variance:\n",
    "\n",
    "- $\\sigma = \\sqrt{Var(X)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation is often preferred because it's in the same units as the original data. In our weather example, if the variance is 25, the standard deviation would be 5°C, giving us a more intuitive measure of variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Properties of Variance](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Non-negativity**: Variance is always non-negative. It's zero only when all values are identical.\n",
    "\n",
    "2. **Scaling**: If we multiply a random variable by a constant c, the variance is multiplied by c^2:\n",
    "   $Var(cX) = c^2 Var(X)$\n",
    "\n",
    "3. **Variance of a sum**: For independent random variables X and Y:\n",
    "   $Var(X + Y) = Var(X) + Var(Y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Examples and Calculations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to our coin flip game where heads wins $10 and tails loses $5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated E[X] = 2.5. Now let's find the variance:\n",
    "\n",
    "- $Var(X) = (10 - 2.5)^2 \\cdot 0.5 + (-5 - 2.5)^2 \\cdot 0.5 = 56.25$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is $\\sqrt{56.25} = 7.5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that while we expect to win $2.50 on average, individual games can deviate quite a bit from this average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[Real-world Application](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance and standard deviation are crucial in many fields:\n",
    "\n",
    "1. In finance, they're used to measure risk. A higher standard deviation in stock returns indicates higher volatility.\n",
    "\n",
    "2. In quality control, they help determine if a manufacturing process is consistent.\n",
    "\n",
    "3. In machine learning, they're used in feature scaling and in algorithms like Gaussian Processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding variance and standard deviation gives us a more complete picture of our data's behavior. While the expected value tells us where the center of our distribution is, variance tells us how spread out it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we'll explore how we can use these concepts to understand relationships between different variables through covariance and correlation. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Covariance and Correlation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're analyzing ice cream sales and temperature data. You might notice that as temperature increases, so do ice cream sales. But how can we quantify this relationship? This is where covariance and correlation come in handy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_'></a>[Covariance: Measuring Relationship](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance measures how two variables change together. It tells us about the direction of the linear relationship between variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random variables X and Y, covariance is defined as:\n",
    "\n",
    "- $Cov(X,Y) = E[(X - E[X])(Y - E[Y])]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, for a sample of n pairs of values, we calculate it as:\n",
    "\n",
    "- $Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})$\n",
    "\n",
    "Where $\\bar{x}$ and $\\bar{y}$ are the sample means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_'></a>[Interpreting Covariance](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive covariance: Variables tend to move in the same direction\n",
    "- Negative covariance: Variables tend to move in opposite directions\n",
    "- Zero covariance: No linear relationship between the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the magnitude of covariance is hard to interpret because it depends on the scales of the variables. This is where correlation comes in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_'></a>[Correlation: Standardized Covariance](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient standardizes covariance, giving us a measure that's easier to interpret. It's defined as:\n",
    "\n",
    "- $\\rho_{X,Y} = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}$\n",
    "\n",
    "Where $\\sigma_X$ and $\\sigma_Y$ are the standard deviations of X and Y.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_'></a>[Interpreting Correlation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation always falls between -1 and 1\n",
    "- 1 indicates perfect positive linear relationship\n",
    "- -1 indicates perfect negative linear relationship\n",
    "- 0 indicates no linear relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our ice cream example, a correlation of 0.8 between temperature and sales would indicate a strong positive relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_5_'></a>[Properties and Examples](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Symmetry**: $Cov(X,Y) = Cov(Y,X)$ and $\\rho_{X,Y} = \\rho_{Y,X}$\n",
    "\n",
    "2. **Covariance with self**: $Cov(X,X) = Var(X)$\n",
    "\n",
    "3. **Correlation with self**: $\\rho_{X,X} = 1$\n",
    "\n",
    "4. **Independence**: If X and Y are independent, $Cov(X,Y) = 0$, but the converse isn't always true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Stock Returns\n",
    "Suppose we have two stocks, A and B. Their daily returns over a week are:\n",
    "\n",
    "- A: 1%, -2%, 3%, -1%, 2%\n",
    "- B: 2%, -1%, 3%, -2%, 1%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating, we find $Cov(A,B) = 0.00255$ and $\\rho_{A,B} = 0.9$. This high positive correlation suggests these stocks tend to move together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_6_'></a>[Real-world Applications](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In finance, correlation between assets is crucial for portfolio diversification\n",
    "2. In machine learning, feature selection often involves analyzing correlations\n",
    "3. In meteorology, understanding correlations helps in weather prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, correlation doesn't imply causation. Ice cream doesn't cause high temperatures! It's just that both are affected by a common factor (warm weather).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding covariance and correlation allows us to quantify relationships between variables, a crucial skill in data analysis and modeling. In our next section, we'll explore higher-order moments, which give us even more tools to describe distributions. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Moments of Random Variables](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Random variable moments are **important concepts in probability theory and statistics** that help describe the characteristics and shape of a probability distribution. They provide valuable information about the distribution's central tendency, spread, skewness, and other properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine trying to describe the shape of a mountain to someone who's never seen it. You might start with its average height, then talk about how spread out it is, whether it's symmetrical, and how steep the slopes are. In the world of probability and statistics, moments play a similar role in describing the shape of probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly used moments are:\n",
    "\n",
    "1. **First Moment (Mean or Expected Value)**\n",
    "\n",
    "    - Represents the *average* or *central value* of the distribution\n",
    "    - Measure of **central tendency**\n",
    "    - Formula:\n",
    "      - Discrete: `E[X] = ∑(x * P(X=x))`\n",
    "      - Continuous: `E[X] = ∫(x * f(x)dx)`\n",
    "\n",
    "2. **Second Central Moment (Variance)**\n",
    "\n",
    "    - Measures the *spread* or *dispersion* of the distribution around the mean\n",
    "    - Average **squared deviation** from the mean\n",
    "    - Formula: `Var(X) = E[(X - E[X])²]`\n",
    "\n",
    "3. **Third Central Moment**\n",
    "\n",
    "    - Used to calculate **skewness**, which measures the *asymmetry* of the distribution\n",
    "    - Interpretation:\n",
    "      - *Positive skew*: longer tail on the right side\n",
    "      - *Negative skew*: longer tail on the left side\n",
    "\n",
    "4. **Fourth Central Moment**\n",
    "\n",
    "    - Used to calculate **kurtosis**, which measures the *\"tailedness\"* or *peakedness* of the distribution\n",
    "    - Indicates whether the distribution has *heavier* or *lighter* tails compared to a normal distribution\n",
    "\n",
    "> Higher-order moments (5th, 6th, etc.) exist but are less commonly used in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term \"moment\" comes from **physics**, where it refers to the product of a distance and a physical quantity. In statistics, it's a similar concept: the product of the random variable raised to a power and its probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding moments is crucial because they provide a way to **characterize probability distributions** without needing to know the entire distribution function. They are particularly useful in *method of moments estimation*, a technique for estimating population parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So moments are a set of quantities that provide information about a distribution's shape. The nth moment of a random variable X is defined as:\n",
    "\n",
    "- $\\mu_n = E[X^n]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the first four moments:\n",
    "\n",
    "1. **First Moment (μ₁)**: This is simply the expected value, E[X]. It represents the center of the distribution.\n",
    "\n",
    "2. **Second Moment (μ₂)**: E[X²]. This is related to the spread of the distribution.\n",
    "\n",
    "3. **Third Moment (μ₃)**: E[X³]. This gives us information about the skewness of the distribution.\n",
    "\n",
    "4. **Fourth Moment (μ₄)**: E[X⁴]. This is related to the kurtosis, or \"peakedness\" of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_'></a>[Central Moments](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central moments are calculated using deviations from the mean. The nth central moment is defined as:\n",
    "\n",
    "- $\\mu_n' = E[(X - E[X])^n]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first central moment is always zero. The second central moment is the variance we discussed earlier. Central moments are often more useful for describing distribution shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_'></a>[Relationships to Other Statistical Measures](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Mean**: First moment, μ₁ = E[X]\n",
    "\n",
    "2. **Variance**: Second central moment, μ₂' = E[(X - E[X])²]\n",
    "\n",
    "3. **Skewness**: Standardized third central moment\n",
    "   $\\gamma_1 = \\frac{E[(X - E[X])^3]}{(E[(X - E[X])^2])^{3/2}}$\n",
    "\n",
    "   - Positive skewness: right tail is longer\n",
    "   - Negative skewness: left tail is longer\n",
    "   - Zero skewness: symmetric distribution\n",
    "\n",
    "4. **Kurtosis**: Related to the fourth central moment\n",
    "   $\\gamma_2 = \\frac{E[(X - E[X])^4]}{(E[(X - E[X])^2])^2} - 3$\n",
    "\n",
    "   - Positive kurtosis: heavier tails than normal distribution\n",
    "   - Negative kurtosis: lighter tails than normal distribution\n",
    "   - Zero kurtosis: similar to normal distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_'></a>[Real-world Application](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding moments is crucial in many fields:\n",
    "\n",
    "1. In finance, skewness and kurtosis are used to assess investment risk beyond just variance.\n",
    "\n",
    "2. In manufacturing, moments help in quality control by characterizing the distribution of product measurements.\n",
    "\n",
    "3. In machine learning, moments are used in method of moments estimation and in designing robust algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in algorithmic trading, a strategy might avoid assets with high positive skewness (rare but extreme positive returns) if the goal is steady, predictable returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moments provide a powerful set of tools for describing and analyzing probability distributions. They allow us to go beyond simple measures of center and spread, giving us a more complete picture of a distribution's shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Conclusion](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap the key concepts we've explored:\n",
    "\n",
    "1. **Expected Value (Mean)**: We learned how to calculate the average outcome of a random variable, a fundamental concept in probability theory.\n",
    "\n",
    "2. **Variance and Standard Deviation**: We discovered how to measure the spread of a distribution, giving us insight into the variability of outcomes.\n",
    "\n",
    "3. **Covariance and Correlation**: We explored how to quantify relationships between variables, a crucial skill in data analysis and modeling.\n",
    "\n",
    "4. **Moments**: We delved into higher-order moments, which provide a comprehensive description of a distribution's shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These concepts form the backbone of descriptive statistics and are fundamental to many areas of data science and machine learning. They allow us to:\n",
    "\n",
    "- Summarize complex datasets succinctly\n",
    "- Make predictions about future outcomes\n",
    "- Assess relationships between variables\n",
    "- Characterize the shape and behavior of probability distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you move forward in your journey through probability and statistics, you'll find these concepts appearing again and again. They're essential tools in the data scientist's toolkit, used in everything from basic data analysis to advanced machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, while these mathematical concepts might seem abstract, they have real-world applications in fields as diverse as finance, physics, social sciences, and technology. Whether you're predicting stock prices, analyzing experimental results, or building recommendation systems, the concepts we've covered today will be invaluable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our next lecture, we'll build on these foundations to explore more advanced topics in probability theory. Keep practicing these concepts, and don't hesitate to revisit this material as needed. The more comfortable you become with these ideas, the more powerful your data analysis skills will become.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}