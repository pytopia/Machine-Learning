{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model persistence is a crucial aspect of machine learning workflows, allowing you to save trained models for future use without the need for retraining. This capability is especially important in production environments where you want to deploy your models efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model persistence refers to the process of saving a trained machine learning model to disk and later loading it for making predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some key benefits of model persistence:\n",
    "1. **Time-saving**: Training complex models can be time-consuming. Persistence allows you to save and reuse models without retraining.\n",
    "2. **Reproducibility**: Saved models ensure consistent results across different sessions or environments.\n",
    "3. **Deployment**: Persistent models can be easily deployed in production systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are several methods for model persistence, we'll focus primarily on joblib in this lecture. However, it's worth briefly mentioning other options:\n",
    "\n",
    "1. **joblib**: Efficient for large NumPy arrays, supports memory mapping.\n",
    "2. pickle: Python's built-in serialization module.\n",
    "3. ONNX: Open Neural Network Exchange format, useful for cross-platform deployment.\n",
    "4. skops.io: A more secure alternative to pickle-based formats.\n",
    "5. cloudpickle: Useful for serializing custom Python code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** joblib is generally the recommended method for scikit-learn model persistence due to its efficiency and ease of use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical workflow for model persistence involves three main steps:\n",
    "\n",
    "1. Train the model\n",
    "2. Save the trained model to disk\n",
    "3. Load the model when needed for predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example using joblib:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([182.67335421,  90.99860656, 166.11347597, 156.03488009,\n",
       "       133.65957541])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from joblib import dump, load\n",
    "\n",
    "# 1. Train the model\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = Ridge()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# 2. Save the model\n",
    "dump(regressor, 'ridge_model.joblib')\n",
    "\n",
    "# 3. Load the model (typically in a different session or script)\n",
    "loaded_model = load('ridge_model.joblib')\n",
    "\n",
    "# Use the loaded model for predictions\n",
    "loaded_model.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with model persistence, keep these points in mind:\n",
    "\n",
    "1. **Compatibility**: Ensure that the scikit-learn version used for loading is compatible with the version used for saving.\n",
    "2. **Dependencies**: All required libraries should be available in the environment where the model is loaded.\n",
    "3. **Security**: Be cautious when loading models from untrusted sources, as malicious code could potentially be executed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** joblib (like pickle) can execute arbitrary code upon loading. Only load models from trusted sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib is particularly well-suited for scikit-learn models because:\n",
    "\n",
    "1. It's optimized for handling large NumPy arrays efficiently.\n",
    "2. It supports compression, making saved files smaller.\n",
    "3. It allows for memory mapping of the persisted data, which can be beneficial when loading large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient model persistence is crucial for deploying machine learning models in real-world applications, where quick loading times and minimal memory usage are often required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections, we'll dive deeper into using joblib for model persistence, exploring its features and best practices to ensure your models are saved and loaded effectively and securely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Saving Models with Pickle](#toc1_)    \n",
    "  - [Basic Usage of Pickle for Model Persistence](#toc1_1_)    \n",
    "  - [Best Practices](#toc1_2_)    \n",
    "- [Version Control and Model Management](#toc2_)    \n",
    "  - [Implementing Version Control for Models](#toc2_1_)    \n",
    "  - [Best Practices for Model Version Control](#toc2_2_)    \n",
    "  - [Model Registry](#toc2_3_)    \n",
    "- [Summary](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Saving Models with Pickle](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While joblib is the recommended method for scikit-learn model persistence, understanding pickle is valuable as it's the underlying serialization protocol used by joblib. Pickle is Python's built-in module for object serialization and deserialization that converts Python objects into a byte stream, allowing them to be saved to disk and later reconstructed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle serializes Python objects by converting them into a stream of bytes. This process is called \"pickling.\" When you load the pickled object, it's \"unpickled\" back into its original form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Basic Usage of Pickle for Model Persistence](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example of how to use pickle to save and load a scikit-learn model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Save the model\n",
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n",
    "# Load the model\n",
    "with open('random_forest_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Use the loaded model\n",
    "loaded_model.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several advantages to using pickle:\n",
    "1. **Native to Python**: No additional libraries required.\n",
    "2. **Versatility**: Can serialize most Python objects, including custom classes.\n",
    "3. **Compact representation**: Efficient for small to medium-sized objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pickle supports different protocols for serialization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Using the highest available protocol\n",
    "with open('model_latest_protocol.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Using a specific protocol (e.g., protocol 4)\n",
    "with open('model_protocol4.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Higher protocol versions are generally more efficient but may not be compatible with older Python versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However, there are some limitations to using pickle:\n",
    "1. **Security Risks**: Pickle can execute arbitrary code during unpickling. Only unpickle data from trusted sources.\n",
    "\n",
    "2. **Version Compatibility**: Pickled objects may not be compatible across different versions of Python or the libraries used (like scikit-learn).\n",
    "\n",
    "3. **Portability**: Pickled objects are not guaranteed to be portable across different platforms or architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** Due to security concerns, never unpickle data from an untrusted or unauthenticated source.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Best Practices](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using pickle, consider the following best practices:\n",
    "1. **Use Protocol 5 or Higher**: For Python 3.8+, use protocol 5 or higher for better performance with large objects.\n",
    "\n",
    "2. **Error Handling**: Always use try-except blocks when unpickling to handle potential errors gracefully.\n",
    "\n",
    "3. **Version Control**: Store information about the Python and library versions used when pickling the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "\n",
    "model_info = {\n",
    "    'model': clf,\n",
    "    'python_version': sys.version,\n",
    "    'sklearn_version': sklearn.__version__\n",
    "}\n",
    "\n",
    "with open('model_with_info.pkl', 'wb') as file:\n",
    "    pickle.dump(model_info, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RandomForestClassifier(),\n",
       " 'python_version': '3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]',\n",
       " 'sklearn_version': '1.5.2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('model_with_info.pkl', 'rb') as file:\n",
    "    model_info = pickle.load(file)\n",
    "\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, while pickle is a powerful and flexible serialization tool, joblib is generally preferred for scikit-learn models due to its optimizations for numerical data and additional features. However, understanding pickle is valuable for general Python object serialization and for insights into how joblib operates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Version Control and Model Management](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective version control and model management are crucial aspects of maintaining a robust machine learning pipeline. These practices ensure reproducibility, traceability, and efficient collaboration in ML projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version control for ML models involves tracking changes to model artifacts, datasets, and associated metadata over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several benefits to version control:\n",
    "\n",
    "1. **Reproducibility**: Ability to recreate exact model versions.\n",
    "2. **Traceability**: Track model lineage and evolution.\n",
    "3. **Collaboration**: Enable team members to work on and share models effectively.\n",
    "4. **Auditing**: Facilitate model audits and compliance checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When managing ML models, consider versioning the following components:\n",
    "\n",
    "1. Model artifacts (saved model files)\n",
    "2. Training data (or references to data versions)\n",
    "3. Model hyperparameters\n",
    "4. Code used for training and evaluation\n",
    "5. Environment details (library versions, etc.)\n",
    "6. Model performance metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Implementing Version Control for Models](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using Git for Code and Small Artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Git is excellent for versioning code and small files. Here's a basic workflow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Initialize a Git repository\n",
    "git init\n",
    "\n",
    "# Add model files and code\n",
    "git add model.joblib train_script.py requirements.txt\n",
    "\n",
    "# Commit changes\n",
    "git commit -m \"Add initial model version 1.0\"\n",
    "\n",
    "# Create a tag for the version\n",
    "git tag -a \"v1.0\" -m \"Model version 1.0\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Use `.gitignore` to exclude large data files or sensitive information from Git repositories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Versioning Large Files with Git LFS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For larger model files, consider using Git Large File Storage (LFS):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Install Git LFS\n",
    "git lfs install\n",
    "\n",
    "# Track large model files with LFS\n",
    "git lfs track \"*.joblib\"\n",
    "\n",
    "# Add and commit as usual\n",
    "git add .gitattributes model.joblib\n",
    "git commit -m \"Add large model file using LFS\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using MLflow for Comprehensive Model Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is a platform for the complete machine learning lifecycle, including experimentation, reproducibility, and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.17.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.17.2 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (1.14.0)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (3.5.2)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (3.9.1)\n",
      "Requirement already satisfied: numpy<3 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (13.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (1.11.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow) (21.2.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (8.1.7)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.40)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (6.8.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (23.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (4.23.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (2.31.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow) (0.5.1)\n",
      "Requirement already satisfied: Mako in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.19)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from Flask<4->mlflow) (1.6.3)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.4.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (2.26.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow) (3.16.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.2.14)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/hejazizo/miniconda3/envs/py310/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.5.1)\n",
      "Downloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: graphql-core, cloudpickle, opentelemetry-api, graphql-relay, docker, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed cloudpickle-3.1.0 databricks-sdk-0.36.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 mlflow-2.17.2 mlflow-skinny-2.17.2 opentelemetry-api-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 00:20:18 INFO mlflow.tracking.fluent: Experiment with name 'iris_classification' does not exist. Creating a new experiment.\n",
      "2024/11/10 00:20:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "mlflow.set_experiment(\"iris_classification\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Load and prepare data\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(clf, \"random_forest_model\")\n",
    "\n",
    "    # Log metrics\n",
    "    accuracy = clf.score(X, y)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** MLflow stores runs and artifacts in a local `mlruns` directory by default. For team collaboration, configure a shared tracking server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Best Practices for Model Version Control](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Semantic Versioning**: Use semantic versioning (e.g., v1.2.3) for model releases.\n",
    "\n",
    "2. **Metadata Tracking**: Include metadata with each model version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_v1.0.0.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import datetime\n",
    "import platform\n",
    "model_metadata = {\n",
    "    'version': '1.0.0',\n",
    "    'trained_on': datetime.datetime.now().isoformat(),\n",
    "    'framework_versions': {\n",
    "        'sklearn': sklearn.__version__,\n",
    "        'python': platform.python_version(),\n",
    "    },\n",
    "    'hyperparameters': clf.get_params(),\n",
    "    'accuracy': accuracy,\n",
    "}\n",
    "\n",
    "joblib.dump((clf, model_metadata), 'model_v1.0.0.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Environment Management**: Use virtual environments and requirements files:\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "conda create -n myenv python=3.10\n",
    "\n",
    "# Activate the environment\n",
    "conda activate myenv\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Save current environment\n",
    "pip freeze > requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Documentation**: Maintain clear documentation for each model version, including:\n",
    "   - Purpose and use case\n",
    "   - Training data description\n",
    "   - Performance metrics\n",
    "   - Known limitations or biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Proper version control and model management ensure that your ML projects are reproducible, traceable, and maintainable over time, which is crucial for both development and production environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[Model Registry](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For production environments, consider implementing a model registry:\n",
    "\n",
    "1. **Central Repository**: Store all production-ready models in a central location.\n",
    "2. **Versioning**: Maintain multiple versions of each model.\n",
    "3. **Metadata**: Store relevant metadata for each model version.\n",
    "4. **Access Control**: Implement proper access controls and approval processes.\n",
    "5. **Deployment Tracking**: Keep track of which model versions are deployed where.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools like MLflow, DVC (Data Version Control), or cloud-based solutions like AWS SageMaker Model Registry can help in setting up a robust model registry system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, effective version control and model management are essential for maintaining a scalable and reliable machine learning pipeline. By implementing these practices, you ensure that your models are trackable, reproducible, and easier to manage throughout their lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Summary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture has covered the essential aspects of model persistence in machine learning, with a focus on scikit-learn models. Here's a concise summary of the key points:\n",
    "\n",
    "1. **Importance of Model Persistence**: Saving and loading models is crucial for deployment, reproducibility, and efficient workflows.\n",
    "\n",
    "2. **Joblib as the Preferred Method**: For scikit-learn models, joblib is recommended due to its efficiency with NumPy arrays and additional features like compression and memory mapping.\n",
    "\n",
    "3. **Pickle as an Alternative**: While less optimal for large models, pickle is a built-in Python solution for general object serialization.\n",
    "\n",
    "4. **Security Considerations**: Always exercise caution when loading models from untrusted sources to avoid potential security risks.\n",
    "\n",
    "5. **Version Control**: Implement proper version control practices for models, including metadata tracking and environment management.\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - Use appropriate file formats (.joblib for joblib, .pkl for pickle)\n",
    "   - Include model metadata when saving\n",
    "   - Ensure consistent environments between saving and loading\n",
    "   - Implement error handling when loading models\n",
    "\n",
    "7. **Advanced Techniques**: Explore options like compression for storage efficiency and memory mapping for large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Always test your model persistence workflow, ensuring that loaded models perform identically to the original ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mastering model persistence, you'll be better equipped to manage the lifecycle of your machine learning models, from development to deployment and maintenance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
