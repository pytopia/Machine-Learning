{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding how data is represented in Scikit-learn is crucial for effectively using the library and building successful machine learning models. This section will introduce you to the fundamental concepts of data representation in Scikit-learn. Proper data representation is the foundation of any machine learning task. It directly impacts the performance of your models and the efficiency of your workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-learn, data representation follows specific conventions that allow for:\n",
    "1. Efficient computation\n",
    "2. Consistency across different algorithms\n",
    "3. Easy integration with other scientific Python libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn primarily uses two main types of data structures:\n",
    "\n",
    "1. **Feature Matrix (X)**: Represents the input features\n",
    "2. **Target Vector (y)**: Represents the output or target variable (for supervised learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (150, 4)\n",
      "Target vector shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Feature matrix\n",
    "y = iris.target  # Target vector\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Always check the shape of your data to ensure it matches Scikit-learn's expectations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is built on top of NumPy, and thus uses NumPy arrays as its primary data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a feature matrix and target vector manually\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "y = np.array([0, 1, 2])\n",
    "\n",
    "print(\"Feature matrix:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target vector:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target vector:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-learn, data is typically organized following the sample-feature convention:\n",
    "\n",
    "- Each row represents a sample (an instance or observation)\n",
    "- Each column represents a feature (an attribute or variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Why This Matters:** This convention allows for intuitive data manipulation and aligns with how most real-world datasets are structured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example of sample-feature convention\n",
    "X = np.array([\n",
    "    [height_1, weight_1, age_1],\n",
    "    [height_2, weight_2, age_2],\n",
    "    [height_3, weight_3, age_3]\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the dimensionality of your data is crucial:\n",
    "\n",
    "- **2D arrays** for feature matrices (n_samples, n_features)\n",
    "- **1D arrays** for target vectors (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix dimensionality: 2D\n",
      "Target vector dimensionality: 1D\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a random classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2)\n",
    "\n",
    "print(f\"Feature matrix dimensionality: {X.ndim}D\")\n",
    "print(f\"Target vector dimensionality: {y.ndim}D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** Scikit-learn expects 2D arrays for X, even when dealing with a single feature. You may need to reshape 1D arrays to 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (5,), Reshaped: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping a 1D array to 2D\n",
    "X_1d = np.array([1, 2, 3, 4, 5])\n",
    "X_2d = X_1d.reshape(-1, 1)\n",
    "print(f\"Original shape: {X_1d.shape}, Reshaped: {X_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn can handle various data types, but it's important to use the appropriate type for each situation:\n",
    "\n",
    "- **Numerical data**: Typically float64 for continuous variables, int64 for discrete\n",
    "- **Categorical data**: Encoded as integers or one-hot encoded\n",
    "- **Text data**: Typically transformed into numerical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll explore these data types in more detail in the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While NumPy arrays are the foundation, Scikit-learn also supports:\n",
    "\n",
    "- **Sparse matrices**: For efficiently handling data with many zero values\n",
    "- **Pandas DataFrames**: For labeled data with mixed types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These advanced data structures will be covered in later sections of this lecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By understanding these fundamental concepts of data representation in Scikit-learn, you'll be well-prepared to work with various datasets and machine learning algorithms effectively. In the next sections, we'll dive deeper into specific aspects of data representation and handling in Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Representation in Scikit-learn](#toc1_)    \n",
    "  - [Feature Matrix (X)](#toc1_1_)    \n",
    "  - [Target Vector (y)](#toc1_2_)    \n",
    "  - [Relationship Between X and y](#toc1_3_)    \n",
    "  - [Handling Mismatch Between X and y](#toc1_4_)    \n",
    "  - [Best Practices](#toc1_5_)    \n",
    "- [Handling Different Data Types](#toc2_)    \n",
    "  - [Numerical Data](#toc2_1_)    \n",
    "  - [Categorical Data](#toc2_2_)    \n",
    "  - [Text Data](#toc2_3_)    \n",
    "  - [Handling Mixed Data Types](#toc2_4_)    \n",
    "- [Sparse Matrices and Their Use Cases](#toc3_)    \n",
    "  - [What are Sparse Matrices?](#toc3_1_)    \n",
    "  - [Types of Sparse Matrices in Scikit-learn](#toc3_2_)    \n",
    "  - [Use Cases for Sparse Matrices](#toc3_3_)    \n",
    "    - [Text Data Representation](#toc3_3_1_)    \n",
    "    - [Large-Scale Machine Learning](#toc3_3_2_)    \n",
    "  - [Working with Sparse Matrices in Scikit-learn](#toc3_4_)    \n",
    "  - [Best Practices and Considerations](#toc3_5_)    \n",
    "- [Working with Pandas DataFrames in Scikit-learn](#toc4_)    \n",
    "  - [Converting DataFrames to Scikit-learn Compatible Format](#toc4_1_)    \n",
    "  - [Using DataFrames Directly with Scikit-learn](#toc4_2_)    \n",
    "  - [Feature Selection with DataFrames](#toc4_3_)    \n",
    "  - [Pipelines with DataFrames](#toc4_4_)    \n",
    "- [Summary](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Data Representation in Scikit-learn](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrices and target vectors are the core data structures used in Scikit-learn for machine learning tasks. Understanding these structures is crucial for effectively preparing and manipulating data for your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/xy.webp\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Feature Matrix (X)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix, typically denoted as X, contains the input variables (features) for your machine learning model. Here are the key characteristics:\n",
    "\n",
    "- 2D array (or matrix)\n",
    "- Shape: (n_samples, n_features)\n",
    "- Each row represents a single sample\n",
    "- Each column represents a specific feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example feature matrix\n",
    "X = np.array(\n",
    "    [\n",
    "        [1.0, 2.0, 3.0],  # Sample 1\n",
    "        [4.0, 5.0, 6.0],  # Sample 2\n",
    "        [7.0, 8.0, 9.0],  # Sample 3\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Feature Matrix:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Always check the shape of your feature matrix to ensure it matches the expected input format of Scikit-learn estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrices can be created from various data sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **NumPy arrays**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Lists of lists**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "X = np.array(X)  # Convert to NumPy array\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Pandas DataFrames**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
    "X = df.values  # Convert to NumPy array\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Target Vector (y)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target vector, usually denoted as y, contains the output or dependent variable that your model aims to predict. Here are the key characteristics:\n",
    "\n",
    "- 1D array\n",
    "- Shape: (n_samples,)\n",
    "- Each element corresponds to a sample in the feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Vector:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Example target vector\n",
    "y = np.array([0, 1, 2])\n",
    "\n",
    "print(\"Target Vector:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target vectors can be of different types depending on the nature of the problem:\n",
    "\n",
    "1. **Binary Classification**:\n",
    "   - Two classes, typically represented as 0 and 1\n",
    "   ```python\n",
    "   y_binary = np.array([0, 1, 1, 0, 1])\n",
    "   ```\n",
    "\n",
    "2. **Multiclass Classification**:\n",
    "   - More than two classes, represented as integers\n",
    "   ```python\n",
    "   y_multiclass = np.array([0, 1, 2, 1, 0, 2])\n",
    "   ```\n",
    "\n",
    "3. **Regression**:\n",
    "   - Continuous values\n",
    "   ```python\n",
    "   y_regression = np.array([0.5, 1.2, 2.3, 1.8, 0.9])\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_'></a>[Relationship Between X and y](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning, there's a direct correspondence between samples in X and y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in X: 3\n",
      "Number of samples in y: 3\n"
     ]
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1.0, 2.0],  # Features for sample 1\n",
    "        [3.0, 4.0],  # Features for sample 2\n",
    "        [5.0, 6.0],\n",
    "    ]\n",
    ")  # Features for sample 3\n",
    "\n",
    "y = np.array(\n",
    "    [\n",
    "        0,  # Target for sample 1\n",
    "        1,  # Target for sample 2\n",
    "        1,\n",
    "    ]\n",
    ")  # Target for sample 3\n",
    "\n",
    "print(f\"Number of samples in X: {X.shape[0]}\")\n",
    "print(f\"Number of samples in y: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Why This Matters:** Ensuring that X and y have the same number of samples is crucial for proper model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_'></a>[Handling Mismatch Between X and y](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common error in machine learning is having mismatched shapes between X and y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Found input variables with inconsistent numbers of samples: [100, 90]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Intentional mismatch\n",
    "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "y = np.random.randint(0, 2, 90)  # Only 90 targets\n",
    "\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model = LogisticRegression().fit(X_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_'></a>[Best Practices](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Consistency Check**: Always verify that the number of samples in X matches the length of y.\n",
    "2. **Reshape if Necessary**: Use `reshape(-1, 1)` for single-feature matrices or single-sample inputs.\n",
    "3. **Use Appropriate Data Types**: Typically float64 for X and int64 for y (in classification tasks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 5), y shape: (100,)\n",
      "X dtype: float64, y dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensuring correct shapes\n",
    "X = np.random.rand(100, 5)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"X dtype: {X.dtype}, y dtype: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mastering the concepts of feature matrices and target vectors, you'll be well-equipped to prepare and manipulate data for various machine learning tasks in Scikit-learn. Remember, proper data representation is the foundation of successful model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Handling Different Data Types](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn can work with various types of data, but it's crucial to understand how to properly represent and handle different data types for optimal model performance. In this section, we'll explore how to work with numerical, categorical, and text data in Scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Numerical Data](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical data is the most straightforward type to work with in Scikit-learn. Scikit-learn works best with float64 data type for numerical features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous numerical data can be used directly in most Scikit-learn estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 2.5, 3.2],\n",
       "       [4.1, 5.7, 6.3],\n",
       "       [7.8, 8.9, 9. ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Continuous numerical data\n",
    "X_continuous = np.array([[1.0, 2.5, 3.2], [4.1, 5.7, 6.3], [7.8, 8.9, 9.0]])\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_continuous)\n",
    "\n",
    "print(\"Original data:\")\n",
    "X_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.1871835 , -1.22474487, -1.25190792],\n",
       "       [-0.07195052,  0.        ,  0.05626552],\n",
       "       [ 1.25913401,  1.22474487,  1.1956424 ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Scaled data:\")\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete numerical data (integers) can also be used directly, but sometimes scaling or encoding might be beneficial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Discrete numerical data\n",
    "X_discrete = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# One-hot encoding for discrete data\n",
    "encoder = OneHotEncoder(sparse_output=True)\n",
    "X_encoded = encoder.fit_transform(X_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original discrete data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original discrete data:\")\n",
    "X_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"One-hot encoded data:\")\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** Consider the nature of your discrete data. If it's ordinal, you might want to use it as is or apply scaling. If it's nominal, one-hot encoding might be more appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Categorical Data](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data requires special handling in Scikit-learn, as most algorithms expect numerical input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ordinal data (categories with a meaningful order), you can use OrdinalEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Ordinal categorical data\n",
    "X_ordinal = np.array(\n",
    "    [[\"cold\", \"warm\", \"hot\"], [\"warm\", \"hot\", \"cold\"], [\"hot\", \"cold\", \"warm\"]]\n",
    ")\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_ordinal_encoded = ordinal_encoder.fit_transform(X_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ordinal data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['cold', 'warm', 'hot'],\n",
       "       ['warm', 'hot', 'cold'],\n",
       "       ['hot', 'cold', 'warm']], dtype='<U4')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original ordinal data:\")\n",
    "X_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded ordinal data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [1., 0., 2.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Encoded ordinal data:\")\n",
    "X_ordinal_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For nominal data (categories without inherent order), use OneHotEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal categorical data\n",
    "X_nominal = np.array(\n",
    "    [[\"red\", \"blue\", \"green\"], [\"blue\", \"green\", \"red\"], [\"green\", \"red\", \"blue\"]]\n",
    ")\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "X_nominal_encoded = onehot_encoder.fit_transform(X_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original nominal data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['red', 'blue', 'green'],\n",
       "       ['blue', 'green', 'red'],\n",
       "       ['green', 'red', 'blue']], dtype='<U5')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original nominal data:\")\n",
    "X_nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded nominal data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"One-hot encoded nominal data:\")\n",
    "X_nominal_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** Be cautious with one-hot encoding for high-cardinality categorical features, as it can lead to the curse of dimensionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[Text Data](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text data requires transformation into numerical features before it can be used in Scikit-learn models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common approach is to use CountVectorizer or TfidfVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample text data\n",
    "text_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"jumps over the lazy dog\",\n",
    "    \"The lazy dog sleeps\"\n",
    "]\n",
    "\n",
    "# Using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Count Vectorizer:\")\n",
    "X_count.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54645401, 0.        , 0.54645401, 0.        , 0.        ,\n",
       "        0.        , 0.54645401, 0.        , 0.32274454],\n",
       "       [0.        , 0.40619178, 0.        , 0.53409337, 0.40619178,\n",
       "        0.53409337, 0.        , 0.        , 0.31544415],\n",
       "       [0.        , 0.4804584 , 0.        , 0.        , 0.4804584 ,\n",
       "        0.        , 0.        , 0.63174505, 0.37311881]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TF-IDF Vectorizer:\")\n",
    "X_tfidf.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Why This Matters:** Choosing the right vectorization method can significantly impact your model's performance on text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_'></a>[Handling Mixed Data Types](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-world scenarios, you often encounter datasets with mixed data types. Here's an approach to handle such cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mixed-type data\n",
    "data = pd.DataFrame({\n",
    "    'age': [30, 40, 50, 60],\n",
    "    'income': [50000, 60000, np.nan, 80000],\n",
    "    'gender': ['M', 'F', 'M', 'F'],\n",
    "    'category': ['A', 'B', 'A', 'C']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing steps for different types of features\n",
    "numeric_features = [\"age\", \"income\"]\n",
    "categorical_features = [\"gender\", \"category\"]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_processed = preprocessor.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (4, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Processed data shape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.34164079, -1.14707867,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.4472136 , -0.22941573,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.4472136 , -0.22941573,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.34164079,  1.60591014,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Processed data:\")\n",
    "X_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach uses ColumnTransformer to apply different preprocessing steps to different columns based on their data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, here are some best practices for handling different data types:\n",
    "1. **Understand Your Data**: Always explore and understand the nature of your features before preprocessing.\n",
    "2. **Scale Numerical Data**: Most models perform better with scaled numerical features.\n",
    "3. **Encode Categorical Data**: Choose between ordinal encoding and one-hot encoding based on the nature of the categories.\n",
    "4. **Handle Text Carefully**: Consider the specifics of your text data when choosing a vectorization method.\n",
    "5. **Use Pipelines**: Combine preprocessing steps with your model in a pipeline to ensure consistent application of transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mastering these techniques for handling different data types, you'll be well-equipped to prepare diverse datasets for machine learning tasks in Scikit-learn, ensuring that your models receive appropriately formatted input for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Sparse Matrices and Their Use Cases](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices are a crucial data structure in Scikit-learn, especially when dealing with high-dimensional data where most of the elements are zero. Understanding sparse matrices can significantly improve the efficiency of your machine learning workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/sparse_dense.gif\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_'></a>[What are Sparse Matrices?](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîë **Key Concept:** A sparse matrix is a matrix in which most of the elements are zero. The central concept is to store only the non-zero elements, saving memory and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 2],\n",
       "       [0, 0, 3, 0],\n",
       "       [4, 0, 0, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Dense matrix with many zeros\n",
    "dense_matrix = np.array([\n",
    "    [1, 0, 0, 2],\n",
    "    [0, 0, 3, 0],\n",
    "    [4, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Convert to sparse matrix\n",
    "sparse_matrix = csr_matrix(dense_matrix)\n",
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sparse matrix:\")\n",
    "sparse_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_'></a>[Types of Sparse Matrices in Scikit-learn](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn primarily uses two types of sparse matrix formats from SciPy:\n",
    "\n",
    "1. **CSR (Compressed Sparse Row)**: Efficient for row slicing and matrix-vector products.\n",
    "2. **CSC (Compressed Sparse Column)**: Efficient for column slicing and matrix-vector products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/sparse-matrix.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/csr-coo.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "\n",
    "# CSR Matrix\n",
    "csr_mat = csr_matrix(dense_matrix)\n",
    "\n",
    "# CSC Matrix\n",
    "csc_mat = csc_matrix(dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CSR Matrix:\")\n",
    "csr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CSC Matrix:\")\n",
    "csc_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** CSR is generally preferred in Scikit-learn due to its efficiency in most operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_'></a>[Use Cases for Sparse Matrices](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices are particularly useful in several scenarios:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_3_1_'></a>[Text Data Representation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with text data, the bag-of-words or TF-IDF representations often result in sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix: (4, 9)\n",
      "Number of stored elements: 21\n",
      "Sparsity: 41.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(\"Shape of sparse matrix:\", X.shape)\n",
    "print(\"Number of stored elements:\", X.nnz)\n",
    "print(\"Sparsity: {:.2f}%\".format(100 * (1 - X.nnz / (X.shape[0] * X.shape[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_3_2_'></a>[Large-Scale Machine Learning](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large datasets, sparse matrices can make certain algorithms feasible that would be impractical with dense representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a large, sparse dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=10000,\n",
    "    n_informative=100,\n",
    "    random_state=42,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],\n",
    ")\n",
    "X[X < 2.5] = 0  # Introduce sparsity\n",
    "X_sparse = csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on sparse matrix\n",
      "Number of non-zero coefficients: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train logistic regression on sparse data\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_sparse, y)\n",
    "\n",
    "print(\"Model trained on sparse matrix\")\n",
    "print(\"Number of non-zero coefficients:\", np.count_nonzero(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_'></a>[Working with Sparse Matrices in Scikit-learn](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Scikit-learn estimators automatically handle sparse input when appropriate. However, it's important to know how to create and manipulate sparse matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a sparse matrix, you can use the `csr_matrix` or `dok_matrix` functions from SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "\n",
    "# From lists\n",
    "row = [0, 0, 1, 2, 2, 2]\n",
    "col = [0, 2, 2, 0, 1, 2]\n",
    "data = [1, 2, 3, 4, 5, 6]\n",
    "sparse_matrix = csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "\n",
    "# Using DOK (Dictionary of Keys) format\n",
    "dok_sparse = dok_matrix((3, 3))\n",
    "dok_sparse[0, 0] = 1\n",
    "dok_sparse[0, 2] = 2\n",
    "dok_sparse[1, 2] = 3\n",
    "dok_sparse[2, 0] = 4\n",
    "dok_sparse[2, 1] = 5\n",
    "dok_sparse[2, 2] = 6\n",
    "\n",
    "csr_from_dok = dok_sparse.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CSR Matrix:\")\n",
    "sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR from DOK:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CSR from DOK:\")\n",
    "csr_from_dok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform element-wise operations on sparse matrices, but be cautious as some operations may convert the matrix to dense format internally, potentially causing memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise operations\n",
    "print(\"Element-wise multiplication:\")\n",
    "sparse_matrix.multiply(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "print(\"Matrix multiplication:\")\n",
    "sparse_matrix.dot(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Why This Matters:** Understanding sparse matrices allows you to handle large, high-dimensional datasets efficiently, enabling you to work with problems that would be intractable with dense representations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_5_'></a>[Best Practices and Considerations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work best with sparse matrices, consider the following:\n",
    "1. **Memory Efficiency**: Use sparse matrices when your data has many zero elements (typically > 90% zeros).\n",
    "2. **Algorithm Compatibility**: Check if the algorithm you're using supports sparse input. Some algorithms may require dense input or have specialized sparse implementations.\n",
    "3. **Conversion Costs**: Be aware of the computational cost of converting between sparse and dense representations. Avoid unnecessary conversions.\n",
    "4. **Appropriate Sparse Format**: Choose the right sparse format (CSR, CSC, etc.) based on your access patterns and operations.\n",
    "5. **Sparse-Aware Feature Selection**: When working with sparse data, consider using sparse-aware feature selection methods to maintain sparsity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** Not all operations are efficient on sparse matrices. Some operations may convert the matrix to dense format internally, potentially causing memory issues for large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By leveraging sparse matrices effectively, you can work with larger datasets, implement more complex models, and solve problems that would be impractical with dense representations. This knowledge is particularly valuable when dealing with text data, high-dimensional feature spaces, or large-scale machine learning tasks in Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Working with Pandas DataFrames in Scikit-learn](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames are a popular and powerful data structure for handling structured data in Python. While Scikit-learn primarily works with NumPy arrays, it also provides seamless integration with Pandas DataFrames. Understanding how to effectively use DataFrames with Scikit-learn can greatly enhance your data preprocessing and machine learning workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames are two-dimensional labeled data structures with columns of potentially different types, similar to a spreadsheet or SQL table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "      <td>4.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>e</td>\n",
       "      <td>5.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C      D\n",
       "0  1  a  1.1   True\n",
       "1  2  b  2.2  False\n",
       "2  3  c  3.3   True\n",
       "3  4  d  4.4  False\n",
       "4  5  e  5.5   True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'C': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'D': [True, False, True, False, True]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of using DataFrames with Scikit-learn:\n",
    "1. **Labeled Data**: DataFrames provide column names, making it easier to keep track of features.\n",
    "2. **Mixed Data Types**: DataFrames can handle multiple data types in different columns.\n",
    "3. **Built-in Data Manipulation**: Pandas offers powerful data manipulation tools.\n",
    "4. **Easy Data Inspection**: DataFrames provide convenient methods for data exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_'></a>[Converting DataFrames to Scikit-learn Compatible Format](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Scikit-learn estimators expect numpy arrays or scipy sparse matrices as input. Here's how to convert DataFrames for numerical data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting only numeric columns\n",
    "numeric_features = ['A', 'C']\n",
    "X = df[numeric_features]\n",
    "\n",
    "# Converting to numpy array\n",
    "X_array = X.values\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    C\n",
       "0  1  1.1\n",
       "1  2  2.2\n",
       "2  3  3.3\n",
       "3  4  4.4\n",
       "4  5  5.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original DataFrame:\")\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 1.1],\n",
       "       [2. , 2.2],\n",
       "       [3. , 3.3],\n",
       "       [4. , 4.4],\n",
       "       [5. , 5.5]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Numpy Array:\")\n",
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.41421356, -1.41421356],\n",
       "       [-0.70710678, -0.70710678],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.70710678,  0.70710678],\n",
       "       [ 1.41421356,  1.41421356]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Scaled Array:\")\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical data, you can use OneHotEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Selecting categorical column\n",
    "cat_features = ['B']\n",
    "X_cat = df[cat_features]\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Categorical Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B\n",
       "0  a\n",
       "1  b\n",
       "2  c\n",
       "3  d\n",
       "4  e"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original Categorical Data:\")\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot Encoded Data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"One-hot Encoded Data:\")\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_'></a>[Using DataFrames Directly with Scikit-learn](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Scikit-learn estimators can work directly with DataFrames, especially those that support feature names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with missing values\n",
    "df_missing = pd.DataFrame(\n",
    "    {\"A\": [1, 2, np.nan, 4], \"B\": [5, np.nan, 7, 8], \"C\": [9, 10, 11, np.nan]}\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_missing), columns=df_missing.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B     C\n",
       "0  1.0  5.0   9.0\n",
       "1  2.0  NaN  10.0\n",
       "2  NaN  7.0  11.0\n",
       "3  4.0  8.0   NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original DataFrame with missing values:\")\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B     C\n",
       "0  1.000000  5.000000   9.0\n",
       "1  2.000000  6.666667  10.0\n",
       "2  2.333333  7.000000  11.0\n",
       "3  4.000000  8.000000  10.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Imputed DataFrame:\")\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Pro Tip:** When using DataFrames directly, Scikit-learn preserves feature names in many preprocessing steps, making it easier to interpret results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_'></a>[Feature Selection with DataFrames](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's feature selection methods can work with DataFrames, maintaining feature names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Creating a DataFrame for feature selection\n",
    "df_features = pd.DataFrame({\n",
    "    'A': np.random.rand(100),\n",
    "    'B': np.random.rand(100),\n",
    "    'C': np.random.rand(100),\n",
    "    'D': np.random.rand(100)\n",
    "})\n",
    "y = np.random.rand(100)  # Target variable\n",
    "\n",
    "# Selecting top 2 features\n",
    "selector = SelectKBest(f_regression, k=2)\n",
    "X_selected = selector.fit_transform(df_features, y)\n",
    "\n",
    "# Getting selected feature names\n",
    "selected_features = df_features.columns[selector.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['A', 'B']\n",
      "Selected Data Shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Selected Data Shape:\", X_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_4_'></a>[Pipelines with DataFrames](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn pipelines can be particularly powerful when working with DataFrames, allowing you to chain multiple preprocessing steps and models while maintaining feature names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Score: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = pd.DataFrame({\n",
    "    'numeric1': np.random.rand(100),\n",
    "    'numeric2': np.random.rand(100),\n",
    "    'categorical': np.random.choice(['A', 'B', 'C'], 100)\n",
    "})\n",
    "y = np.random.randint(0, 2, 100)  # Binary target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), ['numeric1', 'numeric2']),\n",
    "            ('cat', OneHotEncoder(drop='first'), ['categorical'])\n",
    "        ])),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Pipeline Score:\", pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Why This Matters:** Using pipelines with DataFrames allows you to create a clean, reproducible workflow that handles both preprocessing and modeling steps seamlessly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work best with DataFrames, consider the following best practices:\n",
    "\n",
    "1. **Consistent Data Types**: Ensure your DataFrame columns have consistent data types (e.g., all numeric or all categorical).\n",
    "2. **Handle Missing Data**: Address missing values before passing DataFrames to Scikit-learn estimators.\n",
    "3. **Feature Names**: Leverage feature names in DataFrames for better interpretability of your models.\n",
    "4. **Use ColumnTransformer**: For mixed data types, use ColumnTransformer to apply different preprocessing steps to different columns.\n",
    "5. **Check Estimator Compatibility**: Verify if the Scikit-learn estimator you're using can directly handle DataFrames or if conversion to numpy array is necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While many Scikit-learn functions work well with DataFrames, always check the documentation of specific estimators or functions to ensure compatibility and proper usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By effectively integrating Pandas DataFrames with Scikit-learn, you can create more intuitive, readable, and maintainable machine learning workflows. This approach combines the data manipulation power of Pandas with the machine learning capabilities of Scikit-learn, allowing you to handle complex datasets with ease and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Summary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture has covered the essential aspects of data representation in Scikit-learn, providing you with a comprehensive understanding of how to effectively prepare and handle data for machine learning tasks. Let's recap the key points:\n",
    "\n",
    "1. **Feature Matrices and Target Vectors**\n",
    "   - Feature matrix (X): 2D array with shape (n_samples, n_features)\n",
    "   - Target vector (y): 1D array with shape (n_samples,)\n",
    "   - Consistency between X and y is crucial for proper model training\n",
    "\n",
    "2. **Handling Different Data Types**\n",
    "   - Numerical data: Can be used directly, often benefits from scaling\n",
    "   - Categorical data: Requires encoding (ordinal or one-hot)\n",
    "   - Text data: Needs vectorization (e.g., CountVectorizer, TfidfVectorizer)\n",
    "\n",
    "3. **Sparse Matrices**\n",
    "   - Efficient for high-dimensional data with many zero values\n",
    "   - Commonly used in text processing and large-scale machine learning\n",
    "   - CSR and CSC formats are most frequently used in Scikit-learn\n",
    "\n",
    "4. **Working with Pandas DataFrames**\n",
    "   - Provides labeled data structure with mixed data types\n",
    "   - Can be used directly with some Scikit-learn estimators\n",
    "   - Enables seamless integration of data manipulation and machine learning workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper data representation is fundamental to successful machine learning. It impacts model performance, computational efficiency, and interpretability of results.\n",
    "\n",
    "To further enhance your skills in data representation with Scikit-learn:\n",
    "1. Practice with diverse datasets to gain experience with different data types and structures\n",
    "2. Experiment with various preprocessing techniques and observe their impact on model performance\n",
    "3. Explore advanced feature engineering methods to create more informative representations of your data\n",
    "4. Stay updated with Scikit-learn's documentation, as new features and optimizations are regularly added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mastering data representation in Scikit-learn is crucial for building effective machine learning models. It enables you to handle a wide range of data types and sizes, optimize computational resources, and create more robust and interpretable models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By understanding and applying these concepts of data representation, you are well-equipped to tackle complex machine learning tasks efficiently and effectively using Scikit-learn. Remember, the quality and appropriateness of your data representation can often be as important as the choice of algorithm in determining the success of your machine learning projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
